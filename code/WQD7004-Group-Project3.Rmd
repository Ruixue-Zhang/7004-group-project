---
title: "WQD7004_GroupProject"
author: "
- HUIJUN LIU (S2142285)

- RUIXUE ZHANG (S2142119)

- KELVIIN RAJJ KARUPAYA (S2151665)

- LINGYU MENG (S2131391)

- ZUOGE CHEN (S2125783)
"
output:
 rmdformats::readthedown:
 self_contained: true
 thumbnails: true
 lightbox: true
 gallery: false
 highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Group No.: 10

## Group Members

-   LINGYU MENG (S2131391)

-   HUIJUN LIU (S2142285)

-   ZUOGE CHEN (S2125783)

-   KELVIIN RAJJ KARUPAYA (S2151665)

-   RUIXUE ZHANG (S2142119)

## Dataset

-   Title: German Credit Risk

-   Year: 2020

-   Content: This dataset classifies people described by a set of attributes as good or bad credit risks.

-   Source: <https://www.kaggle.com/datasets/kabure/german-credit-data-with-risk>

------------------------------------------------------------------------

-   Title: Sanction Loan

-   Year: 2021

-   Content: This dataset contains features related to predict the loan amount.

-   Source: <https://www.kaggle.com/datasets/zyper26/sanction-loan>

# 1 Introduction

With rising property rates, most people avail home loans to buy their dream houses. Once you have finalized your budget and the house that you want to buy, you must ensure that you have sufficient funds to pay the seller.

Loans are the core business of banks. The main profit comes directly from the loan's interest. The loan companies grant a loan after an intensive process of verification and validation. However, they still don't have assurance if the applicant is able to repay the loan with no difficulties.The bank only lends up to 80% of the total amount based on a person's finances (salary, outgoing expenses, existing loans, etc.). You will need to make the rest of the payment yourself after the bank tells you how much they can lend.

In the German Credit Risk dataset, each entry represents a person who takes a credit by a bank. Each person is classified as good or bad credit risks according to the set of attributes. In the Sanction Loan dataset, we need predict the credit risk level of applicants and the loan amount that can be sanctioned to customers who have applied for a home loan using the features provided.

## 1.1 Project Objective

-   To know the relationship between applicants demographics and the credit amount.

-   To predict the credit risk level of applicants.

-   To predict the loan amount that can be sanctioned to customers who have applied for a home loan using the features provided in the dataset.

## 1.2 Project Question

-   What is the relationship between the variables and the credit amount？

-   What is the relationship between the variables and the bad and good loans？

-   Which model performs best on predicting the credit risk level of applicants? (classification)

-   Which model performs best on predicting the loan amount? (regression)

# 2 Data Pre-processing

## 2.1 German Credit Risk dataset

### 2.1.1 Data Understanding

### Import libraries

```{r import libraries, message=FALSE, warning=FALSE}
library(dplyr)
library(readr)
library(VIM)
library(missForest)
library(Hmisc)
library(caret)
library(ggplot2)
library(e1071)
library(klaR)
library(nnet)
library(Metrics)
library(rpart)
library(rpart.plot)
library(tidyverse)
library(skimr)
library(caret)
library(pROC)
library(DataExplorer)
library(mice)
library(tables)
library(Amelia)
library(car)
library(corrplot)
library(nnet)
library(caTools)
library(ROCR)
library(tree)
library(randomForest)
library(class)
```

### Read data

```{r,message=FALSE}
df = read.csv('german_credit_data.csv', stringsAsFactors = T) 
#df = read.csv(file.choose(), stringsAsFactors = T) 
#Delete the 1st column which is used for indexing.
df=df[,-1]
head(df)

```

### See the structure of dataset

```{r str}
str(df)

```

## 2.1.2 Handle missing data

### Check missing values

```{r check NAs}
print(paste('Complete obs.:',sum(complete.cases(df))))

```

-   Distribution of NAs (by column):

```{r}
colSums(is.na(df))

```

-   Check if any missing value is "" type

```{r}
colSums(df=="")

```

### Visualisation of missing part

```{r VIM}
aggr(df,labels=names(df),col=c('blue','red'),
     numbrs=T,sortVars=T)

```

As shown above, Saving.accounts & Check.account contain missing values, and red color presents missing part.

### Impute NAs

**missForest** is used to impute missing values particularly in the case of mixed-type data. It can be used to impute **continuous and/or categorical** data including complex interactions and nonlinear relations. It yields an out-of-bag (OOB) imputation error estimate. Moreover, it can be run parallel to save computation time.

```{r missForest}
df.mis <- df[!complete.cases(df),]
df.train <- df[complete.cases(df),]
set.seed(42)
df.imp <- missForest(xmis = df.mis, xtrue = df.train, maxiter = 10, ntree = 200)
message('Out of Bag error: ', df.imp$OOBerror)
```

**Save imputation result**

```{r impute}
df.nomis <- df
df.nomis[!complete.cases(df.nomis),] <- df.imp$ximp

```

**Saving.account values distribution after imputation:**

```{r}
table(df.nomis$Saving.accounts)

```

**Checking.account values distribution after imputation:**

```{r}
table(df.nomis$Checking.account)

```

-   Save cleaned dataset

```{r save dataset}
write.csv(df.nomis,file = 'german_credit_data_rmna.csv',row.names=F)

```

-   Summary dataset

```{r summary}
summary(df.nomis)

```

### Descriptions of cleaned dataset

-   Age: (quantitative, in years)
-   Sex: (dichotomous: female, male)
-   Job: (ordinal: 0 - unskilled and non-resident, 1 - unskilled and resident, 2 - skilled, 3 - highly skilled)
-   Housing: (nominal: own, rent, or free)
-   Saving.accounts: (ordinal: little, moderate, quite rich, rich) - Status of existing saving account.
-   Checking.account: (ordinal: little, moderate, rich) - Status of existing checking account.
-   Credit.amount: (quantitative, in D-mark) The maximum amount that the bank is committed to lend.
-   Duration: (quantitative, in month) The specified time to pay the credit.
-   Purpose: (nominal: car, furniture/equipment, radio/TV, domestic appliances, repairs, education, business, vacation/others) - Reasons to get a loan.
-   Risk: (dichotomous : good, bad)

## 2.2 Sanction Loan dataset

### 2.2.1 Data Understanding

### Read data

```{r,message=FALSE}
data = read.csv('train.csv', stringsAsFactors = T) 
#data = read.csv(file.choose(), stringsAsFactors = T) 
#select needed vars for regression model.
data=subset(data, select=c(Age, Income..USD., Loan.Amount.Request..USD.,
                           Current.Loan.Expenses..USD., Credit.Score,
                           Property.Price, Loan.Sanction.Amount..USD., Type.of.Employment))
#rename vars
names(data) <- c('Age','Income','Loan.Amount.Request','Current.Loan.Expenses','Credit.Score','Property.Price','Loan.Sanction.Amount','Employment.Type')
head(data)
```

### See the structure of dataset

```{r}
str(data)
```

## 2.2.2 Handle missing data

### Check missing values

```{r}
print(paste('Complete obs.:',sum(complete.cases(data))))
```

-   Distribution of NAs (by column):

```{r}
colSums(is.na(data))
```

-   Check if any missing value is "" type

```{r}
colSums(data=="")
```

### Visualisation of missing part

```{r}
aggr(data,labels=names(data),col=c('blue','red'),
     numbrs=T,sortVars=T)

```

As shown above, 4 columns contain missing values, and red color presents missing part.

### impute NAs and solve outliers

```{r Income}
# use group median income of employment type to impute income
new <- ave(data$Income, list(data$Employment.Type), FUN=function(x) median(x, na.rm = TRUE))
# smooth anomaly obs
ggplot(data)+
  geom_boxplot(aes(x=Income))
data$Income[is.na(data$Income)] <- new[is.na(data$Income)]
data[data['Income']>120000,'Income']<- median(data[data$Employment.Type==data[data['Income']>120000,'Employment.Type'],'Income'])

```

```{r Current.Loan.Expenses}
data$Current.Loan.Expenses[is.na(data$Current.Loan.Expenses)] <- median(data$Current.Loan.Expenses, na.rm=TRUE)
ggplot(data)+
  geom_boxplot(aes(x=Current.Loan.Expenses))
data[data$Current.Loan.Expenses<0,]$Current.Loan.Expenses <- median(data$Current.Loan.Expenses, na.rm=TRUE)
```

```{r Credit.Score}
data$Credit.Score[is.na(data$Credit.Score)] <- mean(data$Credit.Score, na.rm=TRUE)
ggplot(data)+
  geom_boxplot(aes(x=Credit.Score))
```

```{r Loan.Sanction.Amount}
data$Loan.Sanction.Amount[is.na(data$Loan.Sanction.Amount)] <- 
median(data$Loan.Sanction.Amount, na.rm=TRUE)
ggplot(data)+
  geom_boxplot(aes(x=Loan.Sanction.Amount))
```

```{r}
data=subset(data,select = -c(Employment.Type))
```

-   Save cleaned dataset

```{r save dataset2}
write.csv(data,file = 'train_cleaned.csv',row.names=F)

```

-   Summary dataset

```{r}
summary(data)

```

# 3 Exploratory Data Analysis

## 3.1 General Correlation
```{r}
df.nomis_temp <- df.nomis
df.nomis_temp$Age <- as.numeric(df.nomis_temp$Age)
df.nomis_temp$Sex <- as.numeric(df.nomis_temp$Sex)
df.nomis_temp$Job <- as.numeric(df.nomis_temp$Job)
df.nomis_temp$Housing <- as.numeric(df.nomis_temp$Housing)
df.nomis_temp$Saving.accounts <- as.numeric(df.nomis_temp$Saving.accounts)
df.nomis_temp$Checking.account <- as.numeric(df.nomis_temp$Checking.account)
df.nomis_temp$Credit.amount <- as.numeric(df.nomis_temp$Credit.amount)
df.nomis_temp$Duration <- as.numeric(df.nomis_temp$Duration)
df.nomis_temp$Purpose <- as.numeric(df.nomis_temp$Purpose)
df.nomis_temp$Risk <- as.numeric(df.nomis_temp$Risk)

corrplot(cor(df.nomis_temp),tl.cex = 0.6, method = "color",  addCoef.col="black", number.cex = 0.5)

```

## 3.2 Variables Distribution

### 3.2.1 Continuous Variables Distribution
```{r}
summary(df.nomis[,c(1,7,8)])
par(mfrow = c(2,2))

```

#### Age, Credit.amount, Duration
```{r}
hist(df.nomis$Age, main = "Age", prob = TRUE)
lines(density(df.nomis$Age),col="red")
lines(density(df.nomis$Age, adjust=2), lty="dotted")

hist(df.nomis$Credit.amount, main = "Credit.amount", prob = TRUE)
lines(density(df.nomis$Credit.amount),col="red")
lines(density(df.nomis$Credit.amount, adjust=2), lty="dotted") 

hist(df.nomis$Duration, main = "Duration", prob = TRUE)
lines(density(df.nomis$Duration),col="red")
lines(density(df.nomis$Duration, adjust=3), lty="dotted")

```

### 3.2.2 Discrete Variables Distribution
```{r}
tabular(Sex~1*(n=1 + Percent("col")),data = df.nomis)
tabular(Housing~1*(n=1 + Percent("col")),data = df.nomis)
tabular(Purpose~1*(n=1 + Percent("col")),data = df.nomis)
tabular(Risk~1*(n=1 + Percent("col")),data = df.nomis)

```
```{r}
ggplot(data = df.nomis, aes(Job), main = "Job") + geom_bar(fill="pink") + 
geom_text(aes(label=..count..),stat="count", vjust= 0.1, cex =5)  

ggplot(data = df.nomis, aes(Saving.accounts), main = "Saving.accounts") + geom_bar(fill="pink") + 
geom_text(aes(label=..count..),stat="count", vjust= 0.1, cex =5)  

ggplot(data = df.nomis, aes(Checking.account), main = "Checking.account") + geom_bar(fill="pink") + geom_text(aes(label=..count..),stat="count", vjust= 0.1, cex =5) 

```

## 3.3 Correlations with Credit Risk

### 3.3.1 Age

#### Age and Risk
```{r}
ggplot(df.nomis) + geom_density(aes(Age,fill= Risk),alpha= 0.3)

```

#### Age, Risk and Sex
```{r}
df.nomis %>% ggplot(aes(Sex,Age, fill=Risk)) + geom_boxplot() + scale_y_continuous(breaks = seq(0,100,10))+ scale_fill_manual(breaks = df.nomis$Risk,
values = c("yellow", "red"))

```

#### Age, Risk and Housing
```{r}
df.nomis %>% ggplot(aes(Housing,Age, fill=Risk)) + geom_boxplot() + scale_y_continuous(breaks = seq(0,100,10))+ scale_fill_manual(breaks = df.nomis$Risk,
values = c("yellow", "red"))

```

### 3.3.2 Sex

#### Sex and Risk
```{r}
tabular(Risk*Sex~1*(n=1 + Percent("col")), data=df.nomis)

```
```{r}
df.nomis %>% ggplot(aes(Sex,fill=Risk)) +geom_bar() + geom_text(stat="count", aes(label=..count..,group=Risk), 
position = "stack",vjust=1, cex = 4)+ scale_fill_manual(breaks = df.nomis$Risk,
values = c("yellow", "red"))

```

#### Sex, Risk and Housing 
```{r}
ggplot(aes(x= Sex,fill=Risk),data = df.nomis) +geom_bar() + 
geom_text(stat="count", aes(label=..count..,group=Risk), position = "stack",vjust=1, cex =4) + facet_wrap(~Housing)+ scale_fill_manual(breaks = df.nomis$Risk,
values = c("yellow", "red"))

```

### 3.3.3 Job

#### Job and Risk
```{r}
df.nomis %>% ggplot(aes(x=Job, fill = Risk)) + geom_bar() + geom_text(stat= "count", aes(label=..count.., group = Risk),cex=3.5, vjust=1, position = "stack")+ scale_fill_manual(breaks = df.nomis$Risk,
values = c("yellow", "red"))

```
            
#### Job, Housing and Risk
```{r}
df.nomis %>% ggplot(aes(Job, fill= Risk)) + geom_bar(alpha= 0.3) + facet_wrap(~Housing) 

```

#### Job, Credit.amount and Risk
```{r}
df.nomis %>%  ggplot(aes(Job,Credit.amount, fill=Risk)) + geom_boxplot() + facet_wrap(~Job)+ scale_fill_manual(breaks = df.nomis$Risk,
values = c("yellow", "red"))

```

#### Job, Duration and Risk
```{r}
df.nomis %>%  ggplot(aes(Job,Duration, fill=Risk)) + geom_boxplot() + facet_wrap(~Job)+ scale_fill_manual(breaks = df.nomis$Risk,
values = c("yellow", "red"))

```

### 3.3.4 Housing

#### Housing and Risk
```{r}
tabular(Risk*Housing~1*(n=1 + Percent("col")), data=df.nomis)

```
```{r}
df.nomis %>% ggplot(aes(x= Housing, fill = Risk)) + geom_bar() + geom_text(stat= "count", aes(label=..count.., group = Risk),cex=3.5, vjust=1, position = "stack")+ scale_fill_manual(breaks = df.nomis$Risk,
values = c("yellow", "red"))

```

#### Housing, Duration and Risk
```{r}
df.nomis %>% ggplot(aes(Housing, Duration, fill=Risk)) + geom_boxplot() + scale_fill_manual(breaks = df.nomis$Risk,
values = c("yellow", "red"))

```

#### Housing, Credit.amount and risk
```{r}
df.nomis %>% ggplot(aes(Housing, Credit.amount, fill=Risk)) + geom_boxplot()+ scale_fill_manual(breaks = df.nomis$Risk,
values = c("yellow", "red"))

```

### 3.3.5 Savings.accounts

#### Saving.accounts and Risk
```{r}
df.nomis %>% ggplot(aes(x=Saving.accounts, fill = Risk)) + geom_bar() + geom_text(stat= "count", aes(label=..count.., group = Risk),cex=3.5, vjust=1, position = "stack")+ scale_fill_manual(breaks = df.nomis$Risk,
values = c("yellow", "red"))

```

#### Saving.accounts, Credit.amount and Risk
```{r}
df.nomis %>%  ggplot(aes(Saving.accounts,Credit.amount, fill=Risk)) + geom_boxplot() + facet_wrap(~Saving.accounts)+ scale_fill_manual(breaks = df.nomis$Risk,
values = c("yellow", "red"))

```

### 3.3.6 Checking.account

#### Checking.account and Risk
```{r}
df.nomis %>% ggplot(aes(x=Checking.account, fill = Risk)) + geom_bar() + geom_text(stat= "count", aes(label=..count.., group = Risk),cex=3.5, vjust=1, position = "stack")+ scale_fill_manual(breaks = df.nomis$Risk,
values = c("yellow", "red"))

```

### 3.3.7 Credit.amount

#### Credit.amount and Risk
```{r}
ggplot(df.nomis) + geom_density(aes(Credit.amount,fill= Risk),alpha= 0.3) 

```

#### Credit.amount and Duration
```{r}
df.nomis %>% ggplot(aes(Duration, Credit.amount)) + geom_point()

```

#### Credit.amount and Purpose
```{r}
df.nomis %>% ggplot(aes(Purpose, Credit.amount,fill=Risk)) + geom_boxplot() +facet_wrap(~Risk)+ theme(axis.text.x  = element_text(angle = 45, hjust = 1))+ scale_fill_manual(breaks = df.nomis$Risk,
values = c("yellow", "red"))

```

### 3.3.8 Duration
```{r}
ggplot(df.nomis) + geom_boxplot(aes(Risk,Duration, fill = Risk))+ scale_fill_manual(breaks = df.nomis$Risk,
values = c("yellow", "red"))

```

### 3.3.9 Purpose
```{r}
tabular(Risk*Purpose~1*(n=1 + Percent("col")), data=df.nomis)

```
```{r}
df.nomis %>% ggplot(aes(x= Purpose, fill = Risk)) + geom_bar() + geom_text(stat= "count", aes(label=..count.., group = Risk),cex=3.5, vjust=1, position = "stack") + theme(axis.text.x  = element_text(angle = 45, hjust = 1))+ scale_fill_manual(breaks = df.nomis$Risk,
values = c("yellow", "red"))

```


# 4 Modeling

## 4.1 Regression Model predict loan sanction amount (regression)

```{r}
skim(data)
```

```{r}
# Check the missing data
plot_missing(data)
```

```{r}
class(data)
```

```{r}
head(data)
```

```{r}
# feature engineering
# Train/Test split for Regression
set.seed(42)
train1 <-createDataPartition(y=data$Loan.Sanction.Amount,p=0.7,list=FALSE)

train <- data[train1, ]

test <- data[-train1, ]

```

```{r}
hist(data$Loan.Sanction.Amount,breaks=50)
```

```{r}
# Split dependent variable distribution
hist(train$Loan.Sanction.Amount,breaks=50)
hist(test$Loan.Sanction.Amount,breaks=50)

```

```{r}
# fold cross validation
train_control <- trainControl(method="cv", number=10)
```

### 4.1.1 simple linear regression model (r2 = 0.5201)

```{r}
# the correlation between all vars
cor(data)
# the correlation between target and each feature
data_cor <- cor(data[ , colnames(data) != "Loan.Sanction.Amount"],
                data$Loan.Sanction.Amount)
data_cor

fit <- lm(Loan.Sanction.Amount ~ Loan.Amount.Request,data = data)
summary(fit)
```

```{r}
plot(data$Loan.Amount.Request,data$Loan.Sanction.Amount)
abline(fit) 
```

### 4.1.2 multiple linear regression model (r2 = 0.5764)

```{r}
fit2 <- lm(Loan.Sanction.Amount ~ Age+Income+Loan.Amount.Request+Current.Loan.Expenses+Credit.Score+Property.Price,data = data)
summary(fit2)
```

```{r}
anova(fit,fit2)
```

```{r}
# ridge regression (r2 = 0.5839)
set.seed(42)
model_ridge <- train(Loan.Sanction.Amount ~ Age+Income+Loan.Amount.Request+Current.Loan.Expenses+Credit.Score+Property.Price, data= train, trControl=train_control,method="ridge", metric="RMSE")
model_ridge
```

```{r}
# Least Angle Regression (r2 = 0.5839)
set.seed(42)
model_lars <- train(Loan.Sanction.Amount ~ Age+Income+Loan.Amount.Request+Current.Loan.Expenses+Credit.Score+Property.Price, data= train, trControl=train_control,method="lars", metric="RMSE")
model_lars
```

```{r}
# lasso regression (r2 = 0.5763)
x <- data.matrix(subset(data,select = -c(Loan.Sanction.Amount)))
y <- data$Loan.Sanction.Amount
library(glmnet)

#perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(x, y, alpha = 1)

#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
plot(cv_model)
best_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
coef(best_model)
#use fitted best model to make predictions
y_predicted <- predict(best_model, s = best_lambda, newx = x)

#find SST and SSE
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)

#find R-Squared
rsq <- 1 - sse/sst
rsq
```

Evidently, ridge regression has the smaller RMSE and we will choose it as our prediction model. Similarly, we will confirm whether our model is overfitting.

```{r}
# Make predictions on the testing dataset
x_test_reg <- data[,1:6 ]
y_test_reg <- data[, 7]
prediction_ridge <- predict(model_ridge,x_test_reg)
RMSE(prediction_ridge, y_test_reg)
```

```{r}
# decision tree
colnames(data)
form_reg <- as.formula(
  paste0('Loan.Sanction.Amount~',
         paste(colnames(train)[1:6],collapse="+")
    
  )
)
form_reg
```

```{r}
# training model
set.seed(42)
fit_dt_reg <- rpart(
  form_reg,#formula
  data = train,
  method = "anova",# regression
  control = rpart.control(cp = 0.005)
)
```

```{r}
# Original regression tree
fit_dt_reg
```

```{r}
# Complexity correlation
printcp(fit_dt_reg)
plotcp(fit_dt_reg)

```

```{r}
# After the cut branches
fit_dt_reg_pruned <- prune(fit_dt_reg,cp =0.024)
print(fit_dt_reg_pruned)
```

```{r}
# Variable importance value
fit_dt_reg_pruned$variable.importance
fit_dt_reg$variable.importance

```

```{r}
# Variable importance diagram
varimpdata <- 
  data.frame(importance=fit_dt_reg_pruned$variable.importance)
ggplot(varimpdata,
       aes(x = as_factor(rownames(varimpdata)),y=importance))+
  geom_col()+
  labs(x = 'variables')+
  theme_classic()
```

```{r}
# tree diagram
prp(fit_dt_reg_pruned,
    type=1,
    extra = 101,
    fallen.leaves =TRUE,
    main="Decision Tree")

```

```{r}
# predicted
# The training set predicts the results
trainpred <- predict(fit_dt_reg_pruned,newdata=train)
```

```{r}
# Training set prediction error index
defaultSummary(data.frame(obs = train$Loan.Sanction.Amount,pred=trainpred))
```

```{r}
# Graph the training set predicted results
plot(x=train$Loan.Sanction.Amount,
     y=trainpred,
     xlab="Actual",
     ylab="Prediction",
     main='Comparison of actual and predicted values',
     sub= 'training set')
trainlinmod <- lm(trainpred~train$Loan.Sanction.Amount)
abline(trainlinmod,col="blue",lwd = 2.5,lty='solid')
abline(a=0,b=1,col='red',lwd=2.5,lty='dashed')
legend("topleft",
       legend = c("Model","Base"),
       col  = c("blue","red"),
       lwd = 2.5,
       lty = c("solid","dashed"))
```

```{r}
# Test sets predict results
testpred <- predict(fit_dt_reg_pruned,newdata = test)
```

```{r}
# Test set prediction error index
defaultSummary(data.frame(obs= test$Loan.Amount.Request,pred=testpred))
```

```{r}
# Graph the test set predicted results
plot(x=test$Loan.Sanction.Amount,
     y=testpred,
     xlab="Actual",
     ylab="Prediction",
     main='Comparison of actual and predicted values',
     sub= 'test set')
testlinmod <- lm(testpred~test$Loan.Amount.Request)
abline(testlinmod,col="blue",lwd = 2.5,lty='solid')
abline(a=0,b=1,col='red',lwd=2.5,lty='dashed')
legend("topleft",
       legend = c("Model","Base"),
       col  = c("blue","red"),
       lwd = 2.5,
       lty = c("solid","dashed"))
```

Conclusion: Loan.Amount.Request and Property.Price have a great influence on the target value. We could see both R2 score are about 0.58 and perform almost the same with the model trained on all features. Thus we could predict the Loan.Sanction.Amount with ridge regression model especially considering a vast amount of data.

## 4.2 Classification Model

```{r}
# read data
df = read.csv("german_credit_data_rmna.csv", stringsAsFactors = T)
```

### 4.2.1 Naive Bayes (0.7133)

```{r}
# split into train set and test set
set.seed(42)
index <- sample(2, nrow(df), replace = T, prob = c(0.7, 0.3))
train <- df[index == 1,]
test <- df[index == 2,]
```

```{r}
nb <- naiveBayes(Risk~., data=train, laplace=1)
nb_pred <- predict(nb, test, type = 'class')
table(nb_pred, test$Risk)
confusionMatrix(nb_pred, test$Risk)
```

### 4.2.2 Random Forest (0.7235)

```{r}

rf <- randomForest(Risk ~., 
                                data = train, #train data set 
                                importance = T) 
rf
rf.pred <- predict(rf, test[,-10])
table(observed = test[,10], predicted = rf.pred)
confusionMatrix(rf.pred, test$Risk)
```

### 4.2.3 KNN (0.6519)

```{r}
Xtrain <- train[-10]
Xtrain <- as.data.frame(lapply(Xtrain, as.integer))
Xtest <- test[-10]
Xtest <- as.data.frame(lapply(Xtest, as.integer))
train.label <- as.integer(train$Risk)
test.label <- as.integer(test$Risk)
knn.pred <- knn(train = Xtrain, test = Xtest, cl= train.label,k = 3,prob=TRUE, use.all = T)
confusionMatrix(knn.pred, factor(test.label))
```

### 4.2.4 Conclusion

We got different accuracy scores in the 3 models (Naive Bayes, Random Forest, and KNN). And Random Forest has a best performance which accuracy score is 72.35%.
